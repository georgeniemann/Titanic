{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load functions.py\n",
    "def process_missing(df):\n",
    "    \"\"\"Handle various missing values from the data set\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    holdout = process_missing(holdout)\n",
    "    \"\"\"\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    return df\n",
    "\n",
    "def process_age(df):\n",
    "    \"\"\"Process the Age column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_age(train)\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_fare(df):\n",
    "    \"\"\"Process the Fare column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_fare(train)\n",
    "    \"\"\"\n",
    "    cut_points = [-1,12,50,100,1000]\n",
    "    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_cabin(df):\n",
    "    \"\"\"Process the Cabin column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train process_cabin(train)\n",
    "    \"\"\"\n",
    "    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "    df = df.drop('Cabin',axis=1)\n",
    "    return df\n",
    "\n",
    "def process_titles(df):\n",
    "    \"\"\"Extract and categorize the title from the name column \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_titles(train)\n",
    "    \"\"\"\n",
    "    titles = {\n",
    "        \"Mr\" :         \"Mr\",\n",
    "        \"Mme\":         \"Mrs\",\n",
    "        \"Ms\":          \"Mrs\",\n",
    "        \"Mrs\" :        \"Mrs\",\n",
    "        \"Master\" :     \"Master\",\n",
    "        \"Mlle\":        \"Miss\",\n",
    "        \"Miss\" :       \"Miss\",\n",
    "        \"Capt\":        \"Officer\",\n",
    "        \"Col\":         \"Officer\",\n",
    "        \"Major\":       \"Officer\",\n",
    "        \"Dr\":          \"Officer\",\n",
    "        \"Rev\":         \"Officer\",\n",
    "        \"Jonkheer\":    \"Royalty\",\n",
    "        \"Don\":         \"Royalty\",\n",
    "        \"Sir\" :        \"Royalty\",\n",
    "        \"Countess\":    \"Royalty\",\n",
    "        \"Dona\":        \"Royalty\",\n",
    "        \"Lady\" :       \"Royalty\"\n",
    "    }\n",
    "    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    df[\"Title\"] = extracted_titles.map(titles)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = create_dummies(train,\"Age\")\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    df = process_missing(df)\n",
    "    df = process_age(df)\n",
    "    df = process_fare(df)\n",
    "    df = process_titles(df)\n",
    "    df = process_cabin(df)\n",
    "    df = create_dummies(df, 'Age_categories')\n",
    "    df = create_dummies(df, 'Fare_categories')\n",
    "    df = create_dummies(df, 'Title')\n",
    "    df = create_dummies(df, 'Cabin_type')\n",
    "    df = create_dummies(df, 'Sex')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = process_df(train)\n",
    "holdout = process_df(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data types\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#histograms\n",
    "\n",
    "train_hist_SibSp = plt.hist(train['SibSp'])\n",
    "plt.title('SibSp Histogram')\n",
    "plt.xlabel('Num SibSp')\n",
    "plt.ylabel('Total')\n",
    "plt.show()\n",
    "\n",
    "train_hist_Parch = plt.hist(train['Parch'])\n",
    "plt.title('Parch Histogram')\n",
    "plt.xlabel('Num Parch')\n",
    "plt.ylabel('Total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pivot tables\n",
    "\n",
    "train_pivot_SibSp = train.pivot_table(index='SibSp', values='Survived')\n",
    "train_pivot_SibSp.plot.bar()\n",
    "plt.title('SibSp Pivot')\n",
    "plt.xlabel('Num SibSp')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "train_pivot_Parch = train.pivot_table(index='Parch', values='Survived')\n",
    "train_pivot_Parch.plot.bar()\n",
    "plt.title('Parch Pivot')\n",
    "plt.xlabel('Num Parch')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['ParchSibSp'] = train['Parch'] + train['SibSp']\n",
    "holdout['ParchSibSp'] = holdout['Parch'] + holdout['SibSp']\n",
    "\n",
    "train_hist_ParchSibSp = plt.hist(train['ParchSibSp'])\n",
    "plt.title('ParchSibSp Histogram')\n",
    "plt.xlabel('Num ParchSibSp')\n",
    "plt.ylabel('Total')\n",
    "plt.show()\n",
    "\n",
    "train_pivot_ParchSibSp = train.pivot_table(index='ParchSibSp', values='Survived')\n",
    "train_pivot_ParchSibSp.plot.bar()\n",
    "plt.title('ParchSibSp Pivot')\n",
    "plt.xlabel('Num ParchSibSp')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary\n",
    "## Feature Preparation and Engineering\n",
    "Train and holdout data sets were engineered as follows. Missing values for Fare and Embarked were filled in with the mean and na, respectively. Ages were bucketed into six (6) categories: Missing, Infant , Child, Teenager, Young Adult, Adult, and Senior. Fares were bucketed into four (4) categories: 0-12, 12-50, 50-100, and 100. Cabin Type null values were replaced with 'Unknown'. Titles were extracted from the name column and categorized as: Mr, Mrs, Master, Miss, Officer, and Royalty. Dummy columns were created for the following fields: Age_categories, Fare_categories, Title, Cabin_type, and Sex. Finally, SibSp and Parch columns were summed to obtain a new column describing total number of siblings, spouses, parents, and children per passenger. \n",
    "\n",
    "## Data Exploration\n",
    "### SibSp\n",
    "Integer values with a geometric data distribution. Approximately 600 passengers had no siblings or spouses aboard. About 200 had one (1) sibling or spouse aboard. About 75 had two or more siblings or spouses aboard.\n",
    "\n",
    "SibSp likely correlated with survival rates. Poisson distribution. If no siblings or spouses aboard, survival rate was about 35%. If one (1) or two (2) siblings or spouses were aboard, survival rate increased to 55% and 45%, respectively. If three (3) or more siblings or spouses were aboard, survival rates dropped below 25%.\n",
    "\n",
    "### Parch\n",
    "Integer values with a geometric data distribution. Approximately 675 passengers had no parents or children aboard. About 100 had one (1) parent or child aboard. About 75 had two or more siblings or spouses aboard. About 100 had two (2) parents and/or children aboard. Less than 50 had three (3) or more parents or children aboard.\n",
    "\n",
    "Parch likely correlated with survival rates. Distribution unclear. If no parents or children were aboard, survival rate was about 35%. If one (1) to three (3) parents or children were aboard, survival rate increased to 55 - 60%. If four (4) or more parents or children were aboard, survival rates dropped below 20%.\n",
    "\n",
    "### ParchSibSp\n",
    "Integer values with a geometric data distribution. Approximately 550 passengers had no siblings, spouses, parents, or children aboard. About 150 had one (1) sibling, spouse, parent, or child aboard. About 100 had two (2) siblings, spouses, parents, or children aboard. About 100 had three (3) or more siblings, spouses, parents, or children aboard.\n",
    "\n",
    "ParchSibSp likely correlated with survival rates. Distribution unclear. If no parents, children, siblings, or spouses were aboard, survival rate was about 30%. If one (1) to three (3) parents, children, siblings, or spouses were aboard, survival rate increased to 55% to 70%. If four (4) or more parents, children, siblings, or spouses were aboard, survival rates ranged between 15 -30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_ParchSipSp(df):\n",
    "    \"\"\"Process the ParchSipSp column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_ParchSipSp(train)\n",
    "    \"\"\"\n",
    "    cut_points = [-1, 0, 100]\n",
    "    label_names = [0, 1]\n",
    "    df[\"isalone\"] = pd.cut(df[\"ParchSibSp\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "train = process_ParchSipSp(train)\n",
    "holdout = process_ParchSipSp(holdout)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "def select_features(df):\n",
    "    df = df.select_dtypes([np.number])\n",
    "    all_X = df.drop(['Survived','PassengerId'],axis=1)\n",
    "    all_y = df['Survived']\n",
    "    clf = RandomForestClassifier(random_state=1)\n",
    "    selector = RFECV(clf, cv=10)\n",
    "    selector.fit(all_X, all_y)\n",
    "    optimized_columns = all_X.columns[selector.support_]\n",
    "    \n",
    "    print(optimized_columns)\n",
    "    return optimized_columns\n",
    "    \n",
    "best_features = select_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def select_model(df, feature_list):\n",
    "    all_X = df.loc[:, feature_list]\n",
    "    all_y = df['Survived']\n",
    "    dict_list = [\n",
    "    {\n",
    "        \"name\": \"LogisticRegression\",\n",
    "        \"estimator\": LogisticRegression(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"KNeighborsClassifier\",\n",
    "        \"estimator\": KNeighborsClassifier(),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"n_neighbors\": range(1,20,2),\n",
    "                \"weights\": [\"distance\", \"uniform\"],\n",
    "                \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                \"p\": [1,2]\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RandomForestClassifier\",\n",
    "        \"estimator\": RandomForestClassifier(random_state=1),\n",
    "        \"hyperparameters\":\n",
    "            {\n",
    "                \"n_estimators\": [4, 6, 9],\n",
    "                \"criterion\": [\"entropy\", \"gini\"],\n",
    "                \"max_depth\": [2, 5, 10],\n",
    "                \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                \"min_samples_leaf\": [1, 5, 8],\n",
    "                \"min_samples_split\": [2, 3, 5]\n",
    "            }\n",
    "    }\n",
    "    ]\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for param in dict_list:\n",
    "        print(param['name'])\n",
    "        grid = GridSearchCV(param['estimator'], param_grid = param['hyperparameters'], cv = 10)\n",
    "        grid.fit(all_X, all_y)\n",
    "        best_params = grid.best_params_\n",
    "        print(grid.best_params_)\n",
    "        best_score = grid.best_score_\n",
    "        print(grid.best_score_)\n",
    "        \n",
    "        dict_list[counter]['name'] = param['name']\n",
    "        dict_list[counter]['estimator'] = param['estimator']\n",
    "        dict_list[counter]['hyperparameters'] = best_params\n",
    "        dict_list[counter]['score'] = best_score\n",
    "        \n",
    "        counter = counter + 1\n",
    "        \n",
    "    return dict_list\n",
    "    print('Done')\n",
    "\n",
    "models = select_model(train, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_BestModel = max(models, key=lambda d: d['score'])\n",
    "dict_BestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_submission_file(df, feature_list, dict_BestModel, output_csvFileName):\n",
    "    all_X = df.loc[:, feature_list]\n",
    "    all_y = df['Survived']\n",
    "    \n",
    "    dict_BestModel['estimator'].fit(all_X, all_y)\n",
    "    holdout_predictions = dict_BestModel['estimator'].predict(holdout.loc[:, feature_list])\n",
    "\n",
    "    holdout_ids = holdout[\"PassengerId\"]\n",
    "    submission_df = {\"PassengerId\": holdout_ids,\n",
    "                     \"Survived\": holdout_predictions}\n",
    "    submission = pd.DataFrame(submission_df)\n",
    "    \n",
    "    print(submission[:10])\n",
    "\n",
    "    return submission.to_csv(output_csvFileName, index=False)\n",
    "\n",
    "submission = save_submission_file(train, best_features, dict_BestModel, 'Titantic.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
